{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning\n",
    "- Machine Learning의 한 종류 <br><br>\n",
    "- 여러 층(레이어 , 함수)을 가진 신경망을 사용해 머신러닝을 수행하는 것 <br><br>\n",
    "- 이미지 처리, 음성 인식, 자연어 처리에 중점을 둔다. <br><br>\n",
    "- chatGPT도 딥러닝이다. <br><br>\n",
    "- 1980년대 부터 있었지만, 현대에 와서 컴퓨터 성능 향상으로 각광을 받음 <br><br>\n",
    "\n",
    "### Deep Learning과 Machine Learning의 차이점\n",
    "- 가장 큰 차이점은 특징량(Features) 추출. <br><br>\n",
    "- Machine Learning은 EDA를 통해 feature 추출이 필요 <br><br>\n",
    "- Deep Learning은 따로 추출해줄 필요가 없다. <br><br>\n",
    "- Deep Learning은 데이터의 질이 더 중요하다. <br><br>\n",
    "- 비정형 데이터의 경우에 Deep Learning이 좋고, 정형 데이터의 경우에는 Machine Learning의 경우가 더 좋은 케이스가 많다. <br><br>\n",
    "\n",
    "### 인공신경망 구성\n",
    "- input layer <br><br>\n",
    "- hidden layers <br><br>\n",
    "    - hidden layers 사이에서 가중치가 제공 되는 것이 발생된다. <br><br>\n",
    "    - 이 가중치가 맞는지 안맞는지에 따라서 epoch를 줘서 할 수 있다. <br><br>\n",
    "- output layer <br>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 예제 1 \n",
    "\n",
    "#### 수능점수\n",
    "- 6월에 60점 , 9월에 80점을 맞았다면 수능 때는 몇점을 맞을까?? <br><br>\n",
    "\n",
    "$$y = w_1*x_{6월} + w_2*x_{9월} + b$$\n",
    "\n",
    "- 와 같은 식으로 표현할 수 있다. <br><br>\n",
    "- bias는 왜 필요할까?? 가중치 이외에도 난이도와 같이 영향을 줄 수 있는 상수 값이 있을 수 있으니까 <br><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_1$ $w_2$ 를 둘다 0.5로 하고 $b$ 를 0으로 했을 때에 수능 값과 비교했을 때의 오차를 구해보자."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|사람|6월|9월|수능|오차|\n",
    "|---|---|---|---|---|\n",
    "|철수|60|80|90|20|\n",
    "|영희|50|60|70|15|\n",
    "|민수|60|60|80|20|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이러한 오차값을 줄여나가는 방법이 인공신경망이 하는 부분이다. <br><br>\n",
    "\n",
    "- 총 오차값을 계산하는 알고리즘 <br>\n",
    "    - cross-entropy <br><br>\n",
    "    - binary cross entropy <br><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "- 위와 같이 넣은 값으로 맞추기 힘드니까 이를 가지고 어떠한 값을 계산하고 그 값으로 결과를 도출해 내는 방식 <br><br>\n",
    "- 이 방식이 신경망과 비슷하다 하여 인공신경망이라고 하는 것이다. <br><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 예제 2 \n",
    "\n",
    "#### 스마트폰을 구매할까? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### target \n",
    "- 구매      : y = 1 <br><br>\n",
    "- No 구매   : y = 0 <br><br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature\n",
    "- x1 : 이번달의 수입은 충분? <br><br>\n",
    "- x2 : 최신기능이 있는가? <br><br>\n",
    "- x3 : 기존 스마트폰에 문제가 있는가? <br><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치가 중요하다. \n",
    "- 임의로 정해보자. <br><br>\n",
    "- 부자 : w1 = 1 , w2 = 8 , w3 = 3 <br><br>\n",
    "- 스마트폰 문제 : w1 = 3 , w2 = 2 , w3 = 8 <br><br>\n",
    "\n",
    "\n",
    "#### 내가 느낀 바\n",
    "- case를 안나눠도 여러 단계의 레이어를 통해서 row의 성격이 비슷한 사람끼리 자동적으로 묶어 주는 것 같다.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 총 정리 (Deep Learning을 이용한 계산)\n",
    "- 실제 Data를 이용하여 오차를 구한 후 그 오차들의 합을 구한다. <br><br>\n",
    "- 이 때 오차들의 합이 가장 적었을 때의 w값을 취하면 된다. <br><br>\n",
    "    - 이 걸 epoch를 통해 찾아내는 것 같다. <br><br>\n",
    "- 오차를 구할 때, 뺄셈만 이용하면 minus 값이 발생하는 경우가 발생한다. <br><br>\n",
    "- 이를 해결하기 위해, 절대값 오차 나 평균 제곱 오차를 사용한다. <br><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function (손실 함수)\n",
    "- 이러한 오차를 구하는 함수를 손실 함수라고 한다. <br><br>\n",
    "- 오차를 구하여서 이를 최소화 시키는 방법이다. <br><br>\n",
    "- 모델의 정확도를 평가하는 함수 이다. <br><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function(활성함수)\n",
    "- 히든 레이어를 통해서 새로운 값이 만들어 진다. <br><br>\n",
    "- 이를 계속해서 계산하게 되면 값이 점점 커지게 되는 것이다. <br><br>\n",
    "- 그래서 이를 어떠한 값으로 바꿔서 하는 것이 활성함수 이다. <br><br>\n",
    "- 대표적으로 사용되는 것이 Sigmoid 함수이다. <br><br>\n",
    "\n",
    "### 활성함수의 종류\n",
    "- Sigmoid <br><br>\n",
    "    - 단점 : 값이 커질 때, 이 때 1 이상을 넘지 못하고 작은 값과의 값의 차이가 별로 나지 않아서 오차가 생기게 된다. <br><br>\n",
    "- ReLu <br><br>\n",
    "    - 이미지 처리할 때 많이 사용한다. <br><br>\n",
    "- tanh <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu(x):\n",
    "    if x < 0 :\n",
    "        y = 0\n",
    "    else :\n",
    "        y = x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate \n",
    "- 경사하강법의 단점을 보완하기 위해서 사용한다. <br><br>\n",
    "$$ y = \\alpha * w * x + b $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Optimizer\n",
    "- Momentum : 가속도를 유지 <br><br>\n",
    "    - 일정한 속도로 내려가는 것을 말한다. <br><br>\n",
    "- AdaGrad : 자주 변하는 w는 작게 자주 변하지 않으면 크게 <br><br>\n",
    "    - 관련이 없을 때는 팍팍 내려가다가 손실 오차가 적어지기 시작하면 조금씩 내려가는 거 <br><br>\n",
    "- RMSProp : AdaGrad인데 제곱 <br><br>\n",
    "- Adam : RMSProp + Momentum <br><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순전파 (forward propagation)\n",
    "- 합성함수라고 생각하면 된다. <br><br>\n",
    "\n",
    "### 역전파 (backward propagation)\n",
    "\n",
    "### Drop out\n",
    "- Deep Learning은 기본적으로 과대적합이다. 왜냐?? 히든 레이어를 통해서 많은 가중치가 생기기 때문에 <br><br>\n",
    "- 이렇기에 사용하는 것이 Drop out 이다. <br><br>\n",
    "- 보통 0.4 정도로 사용한다. <br><br>\n",
    "- 어떤 가중치를 쓸지 안쓸지를 정하는 것이다. <br><br>\n",
    "\n",
    "### 조기종료 (early Stopping)\n",
    "- epoch를 실행하면서 손실함수가 줄어들다가 커지기 시작하는 부분에서 종료를 시킨다. - 이를 조기종료 라고 한다. <br><br>\n",
    "- patient를 통해서 몇번 이상 위와 같은 현상이 일어났을 때 종료를 시킬 수 있다. <br><br>\n",
    "    - 왜냐?? epoch 두 개를 통해서 비교를 하기 때문에 한번씩 튈때가 있을지도 모르니까네 <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3680a952170aa4879024e73d39878b7aac962f0b16bced1a9689b2321800c8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
